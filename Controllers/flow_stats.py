import requests
import json
from pprint import pprint
from flask import Flask, request, jsonify
from flask_restful import Resource, Api
import time, threading

app = Flask(__name__)
api = Api(app)

aggregated_flow_stats = []  #global variable that keeps all the stats and gets updated periodically
repeat_time_interval = 1
controller_port_map = {"c1":9000,"c2":9001}

class flows(Resource):
	def get(self):
		return aggregated_flow_stats


def aggregate_flows(flows):
	aggregated_flows = []
	aggregated_matches = []
	for flow in flows:
		flow["match"].pop("in_port",None)
		fail = 0
		for existing_flow in aggregated_flows:
			if sorted(existing_flow["match"].items()) == sorted(flow["match"].items()):
				if flow["switches"][0] not in existing_flow["switches"]:
					existing_flow["switches"].append(flow["switches"][0])
				if flow["controllers"][0] not in existing_flow["controllers"]:
					existing_flow["controllers"].append(flow["controllers"][0])
				fail = 1

				break
		if fail == 0:
			aggregated_flows.append(flow)
	return aggregated_flows

def update_flows(flows):
	for flow in flows:
		found = 0
		for prev_flow in aggregated_flow_stats:
			if flow["match"] == prev_flow["match"]:
				prev_flow = flow
				found = 1
				break
		if not found:
			aggregated_flow_stats.append(flow)


# match, packet_count, byte_count, duration, duration_nsec
def gather_flow_stats():
	flow_stats = []
	for controller in controller_port_map.keys():
		url = 'http://127.0.0.1:'+str(controller_port_map[controller])+"/stats/switches"
		switches = json.loads(requests.get(url).text)	
		for switch in switches:
			url = 'http://127.0.0.1:'+str(controller_port_map[controller])+"/stats/flow/"+str(switch)
			stat = json.loads(requests.get(url).text)
			for flow in stat[str(switch)]:
				if len(flow["match"].keys()) == 6:	#collect stat for the flow generated by traffic ignore other small flows
					flow_stat = {}
					flow_stat["controllers"] = [controller]
					flow_stat["switches"] = [switch]
					flow_stat["match"] = flow["match"]
					flow_stat["byte_count"] = flow["byte_count"]
					# flow_stat["packet_count"] = flow["packet_count"]
					flow_stat["duration_sec"] = flow["duration_sec"]
					# flow_stat["duration_nsec"] = flow["duration_nsec"]
					if flow_stat["duration_sec"] != 0:
						flow_stat["throughput"] = flow_stat["byte_count"] / flow_stat["duration_sec"]
						flow_stats.append(flow_stat)

	aggregated_flows = aggregate_flows(flow_stats)
	update_flows(aggregated_flows)
	threading.Timer(repeat_time_interval, gather_flow_stats).start()

api.add_resource(flows, '/flows')

if __name__ == '__main__':
	gather_flow_stats()
	app.run()